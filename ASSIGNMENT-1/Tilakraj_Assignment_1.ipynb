{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.visitmaryland.org/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "print(\"HTTP Status Code:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "JUzit5PbqZMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b94506-ac97-4c8e-8430-fa45adc31665"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Status Code: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The website returned an HTTP 403 status code, indicating restricted access for automated requests. When extracting visible text, the response contained a bot protection message requesting JavaScript and cookies, confirming that the website blocks non-browser clients"
      ],
      "metadata": {
        "id": "tB6uG51P21Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.visitmaryland.org/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Remove script and style tags\n",
        "for tag in soup([\"script\", \"style\"]):\n",
        "    tag.decompose()\n",
        "\n",
        "# Extract visible text\n",
        "text = soup.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "print(\"\\n--- Visible Text from Maryland Page ---\\n\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "rwjbtPnAqzWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a8f4ef-8a04-4c12-b1c3-cf94dd7fe9f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Visible Text from Maryland Page ---\n",
            "\n",
            "Just a moment...\n",
            "Enable JavaScript and cookies to continue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_nlp = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
        "response_nlp = requests.get(url_nlp, headers=headers)\n",
        "\n",
        "soup_nlp = BeautifulSoup(response_nlp.text, \"html.parser\")\n",
        "\n",
        "print(\"\\n--- Headings from Wikipedia NLP Page ---\\n\")\n",
        "\n",
        "for tag in [\"h1\", \"h2\", \"h3\"]:\n",
        "    for heading in soup_nlp.find_all(tag):\n",
        "        print(heading.get_text(strip=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmHnLtnLtugo",
        "outputId": "02ea0d43-b317-4fda-ad26-10b79aa3ec0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Headings from Wikipedia NLP Page ---\n",
            "\n",
            "Natural language processing\n",
            "Contents\n",
            "History\n",
            "Approaches: Symbolic, statistical, neural networks\n",
            "Common NLP tasks\n",
            "General tendencies and (possible) future directions\n",
            "See also\n",
            "References\n",
            "Further reading\n",
            "External links\n",
            "Symbolic NLP (1950s – early 1990s)\n",
            "Statistical NLP (1990s–present)\n",
            "Statistical approach\n",
            "Neural networks\n",
            "Text and speech processing\n",
            "Morphological analysis\n",
            "Syntactic analysis\n",
            "Lexical semantics (of individual words in context)\n",
            "Relational semantics (semantics of individual sentences)\n",
            "Discourse (semantics beyond individual sentences)\n",
            "Higher-level NLP applications\n",
            "Cognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- All URLs Found on Wikipedia NLP Page ---\\n\")\n",
        "\n",
        "links = soup_nlp.find_all(\"a\", href=True)\n",
        "\n",
        "for link in links[:50]:\n",
        "    print(link[\"href\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htqrzmoQt0P0",
        "outputId": "6c514ad0-fb70-42e9-ea72-b420b469c969"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- All URLs Found on Wikipedia NLP Page ---\n",
            "\n",
            "#bodyContent\n",
            "/wiki/Main_Page\n",
            "/wiki/Wikipedia:Contents\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Special:Random\n",
            "/wiki/Wikipedia:About\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "/wiki/Help:Contents\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Special:RecentChanges\n",
            "/wiki/Wikipedia:File_upload_wizard\n",
            "/wiki/Special:SpecialPages\n",
            "/wiki/Main_Page\n",
            "/wiki/Special:Search\n",
            "https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Natural+language+processing\n",
            "/w/index.php?title=Special:UserLogin&returnto=Natural+language+processing\n",
            "https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Natural+language+processing\n",
            "/w/index.php?title=Special:UserLogin&returnto=Natural+language+processing\n",
            "#\n",
            "#History\n",
            "#Symbolic_NLP_(1950s_–_early_1990s)\n",
            "#Statistical_NLP_(1990s–present)\n",
            "#Approaches:_Symbolic,_statistical,_neural_networks\n",
            "#Statistical_approach\n",
            "#Neural_networks\n",
            "#Common_NLP_tasks\n",
            "#Text_and_speech_processing\n",
            "#Morphological_analysis\n",
            "#Syntactic_analysis\n",
            "#Lexical_semantics_(of_individual_words_in_context)\n",
            "#Relational_semantics_(semantics_of_individual_sentences)\n",
            "#Discourse_(semantics_beyond_individual_sentences)\n",
            "#Higher-level_NLP_applications\n",
            "#General_tendencies_and_(possible)_future_directions\n",
            "#Cognition\n",
            "#See_also\n",
            "#References\n",
            "#Further_reading\n",
            "#External_links\n",
            "https://af.wikipedia.org/wiki/Natuurliketaalverwerking\n",
            "https://ar.wikipedia.org/wiki/%D9%85%D8%B9%D8%A7%D9%84%D8%AC%D8%A9_%D8%A7%D9%84%D9%84%D8%BA%D8%A9_%D8%A7%D9%84%D8%B7%D8%A8%D9%8A%D8%B9%D9%8A%D8%A9\n",
            "https://hyw.wikipedia.org/wiki/%D4%B2%D5%B6%D5%A1%D5%AF%D5%A1%D5%B6_%D4%BC%D5%A5%D5%A6%D5%B8%D6%82%D5%AB_%D5%84%D5%B7%D5%A1%D5%AF%D5%B8%D6%82%D5%B4\n",
            "https://az.wikipedia.org/wiki/T%C9%99bii_dilin_emal%C4%B1\n",
            "https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AD%E0%A6%BE%E0%A6%AC%E0%A6%BF%E0%A6%95_%E0%A6%AD%E0%A6%BE%E0%A6%B7%E0%A6%BE_%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%95%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%9C%E0%A6%BE%E0%A6%A4%E0%A6%95%E0%A6%B0%E0%A6%A3\n",
            "https://zh-min-nan.wikipedia.org/wiki/Ch%C5%AB-ji%C3%A2n_gi%C3%A2n-g%C3%BA_chh%C3%BA-l%C3%AD\n",
            "https://be.wikipedia.org/wiki/%D0%90%D0%BF%D1%80%D0%B0%D1%86%D0%BE%D1%9E%D0%BA%D0%B0_%D0%BD%D0%B0%D1%82%D1%83%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D0%B9_%D0%BC%D0%BE%D0%B2%D1%8B\n",
            "https://be-tarask.wikipedia.org/wiki/%D0%90%D0%BF%D1%80%D0%B0%D1%86%D0%BE%D1%9E%D0%BA%D0%B0_%D0%BD%D0%B0%D1%82%D1%83%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D0%B9_%D0%BC%D0%BE%D0%B2%D1%8B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_paragraph = soup_nlp.find(\"p\").get_text(strip=True)\n",
        "\n",
        "with open(\"nlp_intro.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(first_paragraph)\n",
        "\n",
        "print(\"\\nFirst paragraph saved to nlp_intro.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9XlHb8xt6Mn",
        "outputId": "c484b30f-4d04-4c57-bfc4-427a68abcc8c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First paragraph saved to nlp_intro.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(first_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE5zIps-3Q2L",
        "outputId": "f0acb7f4-48c5-4273-a83e-6007a092e2eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing(NLP) is the processing ofnatural languageinformation by acomputer. NLP is a subfield ofcomputer scienceand is closely associated withartificial intelligence. NLP is also related toinformation retrieval,knowledge representation,computational linguistics, andlinguisticsmore broadly.[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnIPhBVc3uZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}